<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Avedik Ekizyan - CV</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        /* Custom font for a professional look */
        body {
            font-family: 'Inter', sans-serif;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800 py-10">
    <div class="container mx-auto p-6 bg-white rounded-lg shadow-xl max-w-4xl">

        <!-- Header Section -->
        <header class="text-center mb-10">
            <h1 class="text-5xl font-extrabold text-blue-700 mb-2">Avedik Ekizyan</h1>
            <p class="text-xl text-gray-600 mb-4">Neurotechnology & Data Analysis Specialist</p>
            <div class="flex flex-wrap justify-center text-lg">
                <a href="mailto:ekizyan@sfedu.ru" class="text-blue-500 hover:underline flex items-center rounded-md p-1">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-1" viewBox="0 0 20 20" fill="currentColor">
                        <path d="M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z" />
                        <path d="M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z" />
                    </svg>
                    ekizyan@sfedu.ru
                </a>
                <a href="https://scholar.google.com/citations?user=pkhSpG4AAAAJ&hl=ru" target="_blank" class="text-blue-500 hover:underline flex items-center rounded-md p-1">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.102 1.101" />
                    </svg>
                    Google Scholar
                </a>
                <a href="https://www.researchgate.net/profile/Avedik_Ekizyan" target="_blank" class="text-blue-500 hover:underline flex items-center rounded-md p-1">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.102 1.101" />
                    </svg>
                    ResearchGate
                </a>
                <a href="https://mne.discourse.group/u/contamior/activity" target="_blank" class="text-blue-500 hover:underline flex items-center rounded-md p-1">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.102 1.101" />
                    </svg>
                    MNE Forum
                </a>
                <a href="https://t.me/contamior" target="_blank" class="text-blue-500 hover:underline flex items-center rounded-md p-1">
                    <i class="fab fa-telegram-plane h-5 w-5 mr-1"></i>
                    Telegram
                </a>
            </div>
            <!-- Language Switcher -->
            <div class="text-center mt-4">
                <span class="text-lg text-gray-700 font-semibold mr-2">Language:</span>
                <a href="index.html" class="text-blue-700 font-bold hover:underline mx-1">English</a>
                <span class="text-gray-400">|</span>
                <a href="index.ru.html" class="text-blue-500 hover:underline mx-1">Русский</a>
            </div>
        </header>

        <!-- Objective Section -->
        <section class="mb-10 p-6 bg-blue-50 rounded-lg">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Objective</h2>
            <p class="text-lg leading-relaxed">
                Applying my experience in neurotechnology and data analysis to develop innovative solutions in the field of brain-computer interfaces (BCI), neurorehabilitation, and biomedical software engineering.
            </p>
        </section>

        <!-- Education Section -->
        <section class="mb-10">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Education</h2>
            <div class="mb-6 border-b pb-4">
                <h3 class="text-2xl font-semibold text-gray-700">Phd Student, "Mathematical Modeling, Numerical Methods, and Software Systems"</h3>
                <p class="text-lg text-gray-600">Southern Federal University (SFEDU), Vorovich Institute of Mechanics, Mathematics and Computer Science, Rostov-on-Don, Russia</p>
                <p class="text-md text-gray-500">2025 - Present</p>
            </div>
            <div>
                <h3 class="text-2xl font-semibold text-gray-700">Master's Degree, "Biophysics, Bioinformatics and Neurotechnologies"</h3>
                <p class="text-lg text-gray-600">Southern Federal University (SFEDU), Rostov-on-Don, Russia</p>
                <p class="text-md text-gray-500">2023 - 2025</p>
                <p class="text-md text-gray-700 font-medium">Graduated with Honors</p>
                <p class="text-md text-gray-700">Achievements: Nominated for the Zhdanov Medal for outstanding academic and scientific achievements.</p>
            </div>
            <div>
                <h3 class="text-2xl font-semibold text-gray-700">Bachelor's Degree, Physics</h3>
                <p class="text-lg text-gray-600">Southern Federal University (SFEDU), Rostov-on-Don, Russia</p>
                <p class="text-md text-gray-500">2019 - 2023</p>
            </div>
        </section>

        <!-- Additional Education Section -->
        <section class="mb-10 p-6 bg-blue-50 rounded-lg">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Additional Education</h2>
            <div class="text-lg leading-relaxed space-y-4">
                <!-- St Giles -->
                <div>
                    <p class="mb-1">
                        English Language Courses St Giles School, London Highgate<br>
                        <span class="text-sm text-gray-500">17.06.2017 – 11.08.2017</span>
                    </p>
                    <a href="assets/stgiles.png" target="_blank" class="text-blue-600 hover:underline text-sm font-medium flex items-center mt-1">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z" />
                        </svg>
                        View Certificate
                    </a>
                </div>

                <!-- St Andrew’s -->
                <div>
                    <p class="mb-1">
                        English Language Courses St Andrew’s College, Edinburgh<br>
                        <span class="text-sm text-gray-500">30 hours, 13.07.2018 – 27.07.2018</span>
                    </p>
                    <a href="assets/standrews.png" target="_blank" class="text-blue-600 hover:underline text-sm font-medium flex items-center mt-1">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z" />
                        </svg>
                        View Certificate
                    </a>
                </div>

                <!-- Другие курсы (без ссылок) -->
                <div>
                    <p class="mb-1">
                        Additional Professional Education Program "Work with a biohybrid system designed for screening socially significant diseases"<br>
                        <span class="text-sm text-gray-500">Research and Technology Center for Neurotechnologies SFEDU, 27.05.2024 – 01.06.2024</span>
                    </p>
                </div>

                <div>
                    <p class="mb-1">
                        Additional Professional Education Program "Applied Data Analysis in Python"<br>
                        <span class="text-sm text-gray-500">SFEDU, 28.09.2024 – 07.06.2025</span>
                    </p>
                </div>
            </div>
        </section>

        <!-- Work Experience Section -->
        <section class="mb-10">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Work Experience</h2>
            <div class="mb-6 border-b pb-4">
                <h3 class="text-2xl font-semibold text-gray-700">Engineer, Laboratory of Neurotechnologies and Psychophysiology</h3>
                <p class="text-lg text-gray-600">Research and Technology Center for Neurotechnologies, SFEDU, Rostov-on-Don, Russia</p>
                <p class="text-md text-gray-500">March 2025 - July 2025</p>
                <ul class="list-disc list-inside text-lg text-gray-700 mt-2 space-y-1">
                    <li>Developed a software complex in Python for neurophysiological research under high physical loads and prolonged monotonous activity.</li>
                    <li>Utilized a technology stack including Solara, FastAPI, MNE, and MNELsl, to create a robust and user-friendly application.</li>
                    <li>Optimized data collection and processing, significantly increasing the efficiency of research experiments.</li>
                </ul>
            </div>
            <div>
                <h3 class="text-2xl font-semibold text-gray-700">Research Assistant, Laboratory of Neurointerfaces</h3>
                <p class="text-lg text-gray-600">Research and Technology Center for Neurotechnologies, SFEDU, Rostov-on-Don, Russia</p>
                <p class="text-md text-gray-500">July 2023 - March 2025</p>
                <ul class="list-disc list-inside text-lg text-gray-700 mt-2 space-y-1">
                    <li>Processed and analyzed EEG data using Python for classifying imagined speech patterns in brain-computer interface applications.</li>
                    <li>Participated in experimental design and data collection using modern EEG systems.</li>
                    <li>Applied machine learning methods for classifying neurophysiological signals, contributing to the development of new BCI paradigms.</li>
                </ul>
            </div>
        </section>
        
        <!-- Technical Skills Section -->
        <section class="mb-10 p-6 bg-blue-50 rounded-lg">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Technical Skills</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6 text-lg">
                <div>
                    <h3 class="font-semibold text-gray-700 mb-2">Neurophysiology & Neurotechnologies:</h3>
                    <p>Electroencephalography (EEG), Brain-Computer Interface (BCI), Signal Processing, Neurofeedback, Neural Signal Analysis.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-gray-700 mb-2">Programming:</h3>
                    <p>Python (Advanced), Java.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-gray-700 mb-2">Libraries & Frameworks:</h3>
                    <p>MNE, Solara, FastAPI, NumPy, Pandas, Scikit-learn, SciPy, TensorFlow</p>
                </div>
                <div>
                    <h3 class="font-semibold text-gray-700 mb-2">Software & Tools:</h3>
                    <p>Git, LaTeX, Microsoft Office Suite.</p>
                </div>
                <div>
                    <h3 class="font-semibold text-gray-700 mb-2">Languages:</h3>
                    <p>Russian (Native), English (Fluent).</p>
                </div>
            </div>
        </section>
        
        <!-- Projects Section -->
        <section class="mb-12">
            <h2 class="text-3xl font-bold text-blue-800 mb-8 text-center">Projects & Software</h2>

            <div class="flex flex-col gap-8">

                <!-- === PROJECT 1: UII — FULL DETAILED DESCRIPTION === -->
                <div class="bg-white border border-gray-200 rounded-xl shadow-lg overflow-hidden hover:shadow-2xl transition-shadow">
                    <div class="p-6">

                        <h3 class="text-2xl font-bold text-blue-700 mb-3">UII — Experimental Trial Management System</h3>

                        <p class="text-gray-600 mb-4">
                            A real-time platform for managing and monitoring neurophysiological experiments during prolonged monotonous tasks and high physical load conditions.
                        </p>

                        <div class="flex flex-wrap gap-2 mb-4">
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Python</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Solara</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">MNE</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">LSL</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">FastAPI</span>
                        </div>

                        <details class="group">
                            <summary class="flex justify-between items-center cursor-pointer list-none text-blue-600 hover:text-blue-800 font-medium text-sm mb-3">
                                <span class="flex items-center">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 transition-transform group-open:rotate-180" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
                                    </svg>
                                    More about the project
                                </span>
                            </summary>

                            <div class="mt-4 pt-4 border-t border-gray-200 text-gray-700 space-y-4 text-sm leading-relaxed">
                                <p>
                                    UII is a comprehensive software system designed to control and monitor human performance in two critical operational scenarios involving neurophysiological data acquisition and real-time analysis.
                                </p>

                                <div class="space-y-4">
                                    <div>
                                        <p class="font-medium text-gray-800 mb-1">Scenario 1: Prolonged Monotonous Tasks</p>
                                        <ul class="list-disc list-inside space-y-1 ml-4">
                                            <li>Two distinct user roles: Specialist Workstation and Commander Dashboard</li>
                                            <li>Commander connects custom EEG, ECG, and GSR sensors via LSL streams</li>
                                            <li>FastAPI server on the specialist’s PC executes scenario control commands</li>
                                            <li>Specialist receives real-time forecast of professional reliability based on physiological signals</li>
                                            <li>Both interfaces support synchronized data visualization and interaction</li>
                                            <li>Specialist can view own physiological signals and reliability score</li>
                                            <li>Commander can trigger scenario changes, send notifications, and manage session flow</li>
                                        </ul>
                                    </div>

                                    <div>
                                        <p class="font-medium text-gray-800 mb-1">Scenario 2: High Physical Load Conditions</p>
                                        <ul class="list-disc list-inside space-y-1 ml-4">
                                            <li>Single interface: Commander Control Point</li>
                                            <li>Data from specialized wearable ECG sensors with up to 1 km wireless range</li>
                                            <li>Transmitted data is automatically packaged into LSL streams</li>
                                            <li>Real-time visualization of ECG and reliability prediction on commander's screen</li>
                                            <li>No direct feedback to the subject — monitoring is passive</li>
                                            <li>Focus on long-range, robust data transmission under physical stress</li>
                                        </ul>
                                    </div>
                                </div>

                                <p>
                                    The system includes a digital profile creation form for new specialists, allowing storage of personal data, baseline physiological parameters, and experiment history. Additional features include an admin panel for cache management, automatic stream reconnection, HTML/PDF report generation with embedded plots, and a fully responsive, localized user interface with onboarding tooltips and adaptive layout for large screens.
                                </p>

                                <p>
                                    The platform uses Solara for reactive web UI, MNE for EEG processing, and LSL for real-time data streaming. All components are designed for high-reliability deployment in laboratory and field conditions.
                                </p>

                                <!-- Screenshots -->
                                <!-- <div class="grid grid-cols-1 sm:grid-cols-2 gap-3 mt-4">
                                    <a href="https://via.placeholder.com/800x500.png?text=UII+Commander+Dashboard" target="_blank">
                                        <img src="https://via.placeholder.com/800x500.png?text=UII+Commander+Dashboard" alt="Commander Dashboard" class="rounded-lg border hover:border-blue-400 transition-all w-full h-auto">
                                    </a>
                                    <a href="https://via.placeholder.com/800x500.png?text=UII+Specialist+Interface" target="_blank">
                                        <img src="https://via.placeholder.com/800x500.png?text=UII+Specialist+Interface" alt="Specialist Interface" class="rounded-lg border hover:border-blue-400 transition-all w-full h-auto">
                                    </a>
                                </div> -->

                                <!-- Links -->
                                <div class="flex flex-wrap gap-3 text-sm mt-4">
                                    <a href="https://github.com/neuro-sfedu/uii" target="_blank" class="text-blue-600 hover:underline flex items-center">
                                        <i class="fab fa-github mr-1"></i> GitHub (neuro-sfedu/uii)
                                    </a>
                                    <a href="https://github.com/neuro-sfedu/uii/issues" target="_blank" class="text-orange-600 hover:underline flex items-center">
                                        <i class="fas fa-exclamation-triangle mr-1"></i> Open Issues
                                    </a>
                                </div>
                            </div>
                        </details>
                    </div>
                </div>

                <!-- === PROJECT 2: RTSC — FULL DETAILED DESCRIPTION === -->
                <div class="bg-white border border-gray-200 rounded-xl shadow-lg overflow-hidden hover:shadow-2xl transition-shadow">
                    <div class="p-6">

                        <h3 class="text-2xl font-bold text-blue-700 mb-3">RTSC — Train Driver Vigilance Monitoring System</h3>

                        <p class="text-gray-600 mb-4">
                            A real-time vigilance monitoring system for train drivers using a train simulator, photoplethysmography (PPG), and multimodal data visualization.
                        </p>

                        <div class="flex flex-wrap gap-2 mb-4">
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Python</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">PyQt6</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">FastAPI</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">MNE-LSL</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">OpenCV</span>
                        </div>

                        <details class="group">
                            <summary class="flex justify-between items-center cursor-pointer list-none text-blue-600 hover:text-blue-800 font-medium text-sm mb-3">
                                <span class="flex items-center">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 transition-transform group-open:rotate-180" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
                                    </svg>
                                    More about the project
                                </span>
                            </summary>

                            <div class="mt-4 pt-4 border-t border-gray-200 text-gray-700 space-y-4 text-sm leading-relaxed">
                                <p>
                                    RTSC is a specialized monitoring system designed to assess the vigilance and cognitive state of train drivers during simulated train operation. The subject assumes the role of a train driver using a high-fidelity train simulator, while an observer monitors physiological and behavioral data in real time.
                                </p>

                                <p>
                                    The core of the system is a pre-trained classifier that analyzes photoplethysmography (PPG) signals from a wearable sensor to predict the driver’s vigilance level. Classification is performed on a dedicated FastAPI server, which communicates with the main GUI via HTTP, ensuring low-latency, reliable inference.
                                </p>

                                <div class="space-y-3">
                                    <p class="font-medium text-gray-800">Observer Interface Features:</p>
                                    <ul class="list-disc list-inside space-y-1 ml-4">
                                        <li>Live PPG waveform visualization with signal quality indicators</li>
                                        <li>Video feed from driver-facing camera</li>
                                        <li>Audio stream from simulator cabin</li>
                                        <li>Animated vigilance state indicator (color-coded: green/yellow/red)</li>
                                        <li>Real-time classification confidence score</li>
                                        <li>Event logging and timeline navigation</li>
                                        <li>Session recording controls (start/stop)</li>
                                        <li>Configurable alert thresholds</li>
                                    </ul>
                                </div>

                                <p>
                                    The system supports data synchronization via LSL, allowing integration with LabRecorder for offline analysis. All components — GUI, classifier, and media servers — are containerized and deployable in isolated environments.
                                </p>

                                <div class="space-y-3">
                                    <p class="font-medium text-gray-800">Technical Architecture:</p>
                                    <ul class="list-disc list-inside space-y-1 ml-4">
                                        <li>GUI: PyQt6 with pyqtgraph for real-time plotting</li>
                                        <li>Classifier Server: FastAPI with scikit-learn / TensorFlow model</li>
                                        <li>Media Server: FastAPI + OpenCV + PyAudio for video/audio streaming</li>
                                        <li>Data Pipeline: LSL → MNE-LSL → LabRecorder</li>
                                        <li>Deployment: start.cmd, conda/Python 3.9+, VideoServer.exe</li>
                                        <li>Configuration: JSON config files, baseline .npz files</li>
                                        <li>Recording: Automatic data save to data/ folder</li>
                                    </ul>
                                </div>

                                <!-- Screenshot -->
                                <!-- <div class="grid grid-cols-1 gap-3 mt-4">
                                    <a href="https://github.com/user-attachments/assets/5b500006-5a9c-499a-b2ff-65dedddd9077" target="_blank">
                                        <img src="https://github.com/user-attachments/assets/5b500006-5a9c-499a-b2ff-65dedddd9077" alt="RTSC Observer Interface" class="rounded-lg border hover:border-blue-400 transition-all w-full h-auto">
                                    </a>
                                </div> -->

                                <!-- Links -->
                                <div class="flex flex-wrap gap-3 text-sm mt-4">
                                    <a href="https://github.com/AvedikEkiz/RTSC" target="_blank" class="text-blue-600 hover:underline flex items-center">
                                        <i class="fab fa-github mr-1"></i> GitHub (AvedikEkiz/RTSC)
                                    </a>
                                </div>
                            </div>
                        </details>
                    </div>
                </div>

                <!-- === PROJECT 3: Learning to Speak — FULL DETAILED DESCRIPTION === -->
                <div class="bg-white border border-gray-200 rounded-xl shadow-lg overflow-hidden hover:shadow-2xl transition-shadow">
                    <div class="p-6">

                        <h3 class="text-2xl font-bold text-blue-700 mb-3">Learning to Speak — Speech Therapy App</h3>

                        <p class="text-gray-600 mb-4">
                            Android app for children with speech delay. Includes interactive games with speech-to-text and animated feedback.
                        </p>

                        <div class="flex flex-wrap gap-2 mb-4">
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Flutter</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Dart</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Speech-to-Text</span>
                            <span class="px-3 py-1 bg-blue-100 text-blue-700 text-xs font-medium rounded-full">Android</span>
                        </div>

                        <details class="group">
                            <summary class="flex justify-between items-center cursor-pointer list-none text-blue-600 hover:text-blue-800 font-medium text-sm mb-3">
                                <span class="flex items-center">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 transition-transform group-open:rotate-180" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
                                    </svg>
                                    More about the project
                                </span>
                            </summary>

                            <div class="mt-4 pt-4 border-t border-gray-200 text-gray-700 space-y-4 text-sm leading-relaxed">
                                <p>
                                    Learning to Speak is a mobile application designed to support speech development in children with speech delays. It features three interactive games that combine animation, voice prompts, and real-time speech recognition to encourage articulation and motor control.
                                </p>

                                <div class="space-y-4">
                                    <div>
                                        <p class="font-medium text-gray-800 mb-1">Game 1: Feed the Animals</p>
                                        <ul class="list-disc list-inside space-y-1 ml-4">
                                            <li>Animated animal appears on screen with expressive eyes and mouth</li>
                                            <li>Voice prompt: "Say 'meow' to feed the cat"</li>
                                            <li>Speech-to-text model analyzes child's pronunciation in real time</li>
                                            <li>Correct sound → animal eats, cheers, and shows happiness</li>
                                            <li>Incorrect → gentle prompt to try again with visual cue</li>
                                            <li>Currently supports 10 animals: cat, dog, cow, sheep, horse, pig, duck, chicken, lion, elephant</li>
                                            <li>Each animal has unique sound, animation, and food item</li>
                                        </ul>
                                    </div>

                                    <div>
                                        <p class="font-medium text-gray-800 mb-1">Game 2: Funny Faces Workout</p>
                                        <ul class="list-disc list-inside space-y-1 ml-4">
                                            <li>Animated female character demonstrates facial exercises</li>
                                            <li>Prompts include: "Stick out your tongue", "Purse your lips", "Kiss", "Look surprised", "Smile wide"</li>
                                            <li>Child imitates in front of front camera</li>
                                            <li>Visual feedback with stars, sounds, and character applause</li>
                                            <li>Progress bar fills with each successful repetition</li>
                                            <li>Focus on articulatory gymnastics and oral motor skills</li>
                                        </ul>
                                    </div>

                                    <div>
                                        <p class="font-medium text-gray-800 mb-1">Game 3: Copy the Pose</p>
                                        <ul class="list-disc list-inside space-y-1 ml-4">
                                            <li>Animated character strikes a full-body pose (arms up, jump, etc.)</li>
                                            <li>Child must repeat the body position</li>
                                            <li>Camera-based pose detection (planned for future update)</li>
                                            <li>Progress tracking per session with stars and rewards</li>
                                            <li>Encourages gross motor imitation alongside speech</li>
                                        </ul>
                                    </div>
                                </div>

                                <p>
                                    Built with Flutter for cross-platform compatibility with primary focus on Android. Uses Google Speech-to-Text API for real-time sound analysis. Includes progress tracking, parental reports, customizable difficulty levels, and child-friendly UI with large buttons and bright colors.
                                </p>

                                <!-- Screenshots -->
                                <!-- <div class="grid grid-cols-1 sm:grid-cols-2 gap-3 mt-4">
                                    <a href="https://via.placeholder.com/400x800.png?text=Feed+the+Cat" target="_blank">
                                        <img src="https://via.placeholder.com/400x800.png?text=Feed+the+Cat" alt="Feed the Animals" class="rounded-lg border hover:border-blue-400 transition-all w-full h-auto">
                                    </a>
                                    <a href="https://via.placeholder.com/400x800.png?text=Funny+Faces" target="_blank">
                                        <img src="https://via.placeholder.com/400x800.png?text=Funny+Faces" alt="Funny Faces" class="rounded-lg border hover:border-blue-400 transition-all w-full h-auto">
                                    </a>
                                </div> -->

                                <!-- Links -->
                                <div class="flex flex-wrap gap-3 text-sm mt-4">
                                    <a href="#" target="_blank" class="text-green-600 hover:underline flex items-center">
                                        <i class="fab fa-google-play mr-1"></i> Google Play (coming soon)
                                    </a>
                                    <a href="#" target="_blank" class="text-blue-600 hover:underline flex items-center">
                                        <i class="fab fa-github mr-1"></i> GitHub (private)
                                    </a>
                                </div>
                            </div>
                        </details>
                    </div>
                </div>

            </div>
        </section>

        <!-- Publications & Patents Section -->
        <section class="mb-10">
            <h2 class="text-3xl font-bold text-blue-800 mb-4">Publications & Patents</h2>
            <div class="mb-6">
                <h3 class="text-2xl font-semibold text-gray-700 mb-3">Scopus Publications:</h3>
                <ul class="list-disc list-inside text-lg text-gray-700 space-y-2">
                    <li>Ekizyan, A.K., Shaposhnikov, P.D., Kostulin, D.V., Shevchenko, I.G., Shaposhnikov, D.G. (2026). Enhanced EEG Inner Speech Classification Across Languages Using Coherence-Based Features. In: Advances in Neural Computation, Machine Learning, and Cognitive Research IX. Studies in Computational Intelligence, vol 1241. Springer, Cham.<a href="https://doi.org/10.1007/978-3-032-07690-8_46" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li> 
                    <li>Kostulin, D. V., Shaposhnikov, P. D., Ekizyan, A. K., Shevchenko, M. G., Shaposhnikov, D. G. (2026). Multimodal Machine Learning Approach to Classification of Operator’s Psychophysiological States During Monotonous Activity Based on EEG and ECG Data. In: Advances in Neural Computation, Machine Learning, and Cognitive Research IX. Studies in Computational Intelligence, vol 1241. Springer, Cham.<a href="https://doi.org/10.1007/978-3-032-07690-8_48" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li>
                    <li>Ekizyan, A. K., Shaposhnikov, P. D., Kostulin, D. V., Shaposhnikov, D. G., & Kiroy, V. N. (2023, October). Real-Time Movement-Related EEG Phenomena Detection for Portable BCI Devices. Neural Network Approach. In International Conference on Neuroinformatics (pp. 157-164). Cham: Springer Nature Switzerland. <a href="https://doi.org/10.1007/978-3-031-44865-2_17" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li>
                    <li>Ekizyan, A. K., Shaposhnikov, P. D., Kostulin, D. V., Shevchenko, I. G., & Shaposhnikov, D. G. (2024, October). EEG Inner Speech Classification Using Machine Learning Cascade Model. In International Conference on Neuroinformatics (pp. 295-302). Cham: Springer Nature Switzerland. <a href="https://doi.org/10.1007/978-3-031-80463-2_27" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li>
                    <li>Kostulin, D. V., Shaposhnikov, P. D., Ekizyan, A. K., Nazarov, A. D., Shevchenko, I. G., Shaposhnikov, D. G., & Kiroy, V. N. (2024, October). Detection of Spatial-Frequency Localization of Inner Speech EEG-Patterns. In International Conference on Neuroinformatics (pp. 303-316). Cham: Springer Nature Switzerland. <a href="https://doi.org/10.1007/978-3-031-80463-2_28" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li>
                </ul>
            </div>
            <div class="mb-6">
                <h3 class="text-2xl font-semibold text-gray-700 mb-3">RSCI Publications (Russian Science Citation Index):</h3>
                <ul class="list-disc list-inside text-lg text-gray-700 space-y-2">
                    <li>Nazarov, A. D., Ekizyan, A. K., Shaposhnikov, P. D. (2023). Development of a stimulus-independent ergonomic neurointerface for controlling a bionic hand prosthesis. In Prospective systems and control problems: Proceedings of the XVIII All-Russian scientific and practical conference. Taganrog: Lukomorye Publishing House. pp. 197-201. <a href="https://elibrary.ru/qndlvi" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[Link]</a> <!-- Please replace '#' with the actual URL for this publication --></li>
                    <li>Nazarov, A. D., Zolotukhin, V. V., Kostulin, D. V., et al. (2024). Application of PDMS/CNT composite as a dry electrode for bioelectrical activity registration. In Twenty-Eighth All-Russian Scientific Conference of Physics Students and Young Scientists. Novosibirsk: Association of Physics Students and Young Scientists of Russia. p. 209. <a href="https://elibrary.ru/ffgkpr" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[Link]</a> <!-- Please replace '#' with the actual URL for this publication --></li>
                    <li>Shaposhnikov, D. G., Ekizyan, A. K., Shaposhnikov, P. D. (2024). Development of software for generating control commands from EEG patterns of imagined speech in stimulus-independent neurointerface circuits. In Neuroscience for medicine and psychology: Proceedings of the XX International Interdisciplinary Congress. Moscow: OOO "MAKS Press". p. 316. DOI: 10.29003/m4074.sudak.ns2024-20/316. <a href="https://doi.org/10.29003/m4074.sudak.ns2024-20/316" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[DOI]</a></li>
                    <li>Ekizyan, A. Kh. Scalable research applications based on ipywidgets / A. Kh. Ekizyan, D. N. Shcherbina // Modern Information Technologies: Trends and Prospects of Development : Materials of the XXXII Scientific Conference, Rostov-on-Don, April 17–19, 2025. – Rostov-on-Don: Southern Federal University, 2025. – P. 514-515. – EDN ZWYXED. <a href="https://elibrary.ru/item.asp?id=82785167&pff=1" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">[Link]</a></li>
                </ul>
            </div>
            <div>
                <h3 class="text-2xl font-semibold text-gray-700 mb-3">Certificates of State Registration of Computer Programs:</h3>
                <ul class="list-disc list-inside text-lg text-gray-700 space-y-2">
                    <li>Certificate No. 2023688271: Program for t-SNE cluster analysis. Date of issue: December 21, 2023. Authors: Shevchenko I. G., Shaposhnikov P. D., Kostulin D. V., et al.</li>
                    <li>Certificate No. 2024669356: Program for R-peak identification and statistical analysis of electrocardiographic data. Date of issue: August 16, 2024. Authors: Shaposhnikov D. G., Shevchenko I. G., Shaposhnikov P. D., et al.</li>
                    <li>Certificate No. 2024684925: Program for real-time determination of falling asleep and sleep states based on ECG. Date of issue: October 22, 2024. Authors: Shaposhnikov D. G., Shevchenko I. G., Shaposhnikov P. D., et al.</li>
                </ul>
            </div>
        </section>

        <!-- Footer Section -->
        <footer class="text-center text-gray-500 text-sm mt-10">
            <p>&copy; <script>document.write(new Date().getFullYear())</script> Avedik Ekizyan. All rights reserved.</p>
        </footer>

    </div>
</body>
</html>
